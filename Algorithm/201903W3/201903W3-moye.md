# 外部排序

Author： Moye

题目：有10个文件，每个文件有1000万行，文件内容的每一行为一个整型数字；需要，写一个程序，将所有数字排序，分为10个文件输出。


## 数据生成
```python
import asyncio
import random
import psutil
import os


interval = 1e+7


async def write_data(arg):
    # 每个协程将1千万的数据写进文件
    _start = int(arg[0])
    _end = int(arg[1])
    _filename = arg[2]
    with open(_filename, 'at') as file:
        # 打开文件，将乱序的数据写入文件
        _range = list(range(_start, _end))
        random.shuffle(_range)
        for _num in _range:
            file.write(str(_num) + "\n")


def run_as_asyncio(data_list):
    # 创建协程，减小线程切换的开销
    _tasks = []
    for d in data_list:
        _start_num = d[0]
        # 创建协程任务
        while _start_num < d[1]:
            _tasks.append(write_data((_start_num, _start_num + interval//100, d[2])))
            _start_num += interval//100
    _loop = asyncio.new_event_loop()
    asyncio.set_event_loop(_loop)
    _loop.run_until_complete(asyncio.wait(_tasks))
    _loop.close()


if __name__ == '__main__':
    num = 0
    time = 0
    data = []
    # 初始化数据范围以及对应的数据文件名
    while num < interval*10:
        filename = str(time)+"-data.txt"
        # （start， end， filename）
        data.append((num, num + interval, filename))
        num += interval
        time += 1
    # 使用协程创建数据
    run_as_asyncio(data)
    print('内存使用：{} Mb'.format(psutil.Process(os.getpid()).memory_info().rss/(1024**2)))

```

## 排序
```python
import threading
import random
import asyncio
import psutil
import os
import time

interval = 2.5e+5


def merge_sort(tmp_file_list):
    """
    文件归并排序入口
    :param tmp_file_list: tmp 文件名列表
    :return: 合并后的文件名
    """
    if len(tmp_file_list) == 1:
        return tmp_file_list[0]
    num = len(tmp_file_list) // 2
    left_filename = merge_sort(tmp_file_list[:num])
    right_filename = merge_sort(tmp_file_list[num:])
    return merge_process(left_filename, right_filename)


def merge_process(left_filename, right_filename):
    """
    合并两个临时文件中的数据
    :param left_filename: 临时数据文件1
    :param right_filename: 临时数据文件2
    :return:
    """
    flag = True
    is_while = True
    ans_filename = left_filename + "+" + right_filename[-3:] + str(random.randint(0, 1000))
    with open(left_filename, 'rt') as left, open(right_filename, 'rt') as right, open(ans_filename, "wt") as target:
        # 合并两个 tmp 文件中的数据
        _l, _r = "", ""
        # 判断文件是否有空文件
        try:
            _l = int(left.readline())
        except ValueError:
            is_while = False
            flag = False
        try:
            _r = int(right.readline())
        except ValueError:
            is_while = False
            flag = True
        while is_while:
            # 外部文件的归并排序
            if _l <= _r:
                target.write(str(_l) + "\n")
                tmp = left.readline()
                try:
                    _l = int(tmp)
                except ValueError:
                    if tmp == "\n":
                        continue
                    flag = False
                    break
            else:
                target.write(str(_r) + "\n")
                tmp = right.readline()
                try:
                    _r = int(tmp)
                except ValueError:
                    if tmp == "\n":
                        continue
                    flag = True
                    break
        if flag:
            # 将已读的合法数据写进文件
            if _l != "" and _l != "\n":
                target.write(str(_l).replace("\n", ""))
            # 将剩余合法数据写进文件
            for i in left:
                if i == "" or i == "\n":
                    continue
                target.write("\n" + str(i).replace("\n", ""))
        else:
            # 将已读的合法数据写进文件
            if _r != "" and _r != "\n":
                target.write(str(_r).replace("\n", ""))
            # 将剩余合法数据写进文件
            for i in right:
                if i == "" or i == "\n":
                    continue
                target.write("\n" + str(i).replace("\n", ""))
    # 删除多余的临时文件
    os.remove(right_filename)
    os.remove(left_filename)
    # 返回合并后的结果文件名
    return ans_filename


def merge_file_data(filename):
    """
    调用归并排序
    :param filename: 目标数据文件名
    :return: None
    """
    filename = filename + "tmp"
    tmp_filename_list = []
    for file in os.listdir():
        if file.startswith(filename):
            tmp_filename_list.append(file)
    tmp = merge_sort(tmp_filename_list)
    os.rename(tmp, filename.split(".")[0] + '-' + "ans.txt")


async def write_data_in_tmp_file(data, filename):
    """
    将数据排序后写入临时文件
    :param data:
    :param filename:
    :return:
    """
    data.sort()
    with open(filename, 'wt') as f:
        f.write(str(data[0]))
        for i in data[1:]:
            f.write("\n"+str(i))


async def process(filename):
    with open(filename, "rt") as f_lines:
        counter = 0
        name_num = 1
        number_data = []
        for number in f_lines:
            # 保存读取的数据
            number_data.append(int(number))
            counter += 1
            # 每25w数据保存指tmp文件
            if counter >= interval:
                _filename = threading.current_thread().getName()+"tmp"+str(name_num)
                # 写进tmp文件
                await write_data_in_tmp_file(number_data, _filename)
                # 重新计数
                counter = 0
                number_data = []
                name_num += 1
    merge_file_data(filename)
    loop = asyncio.get_event_loop()
    loop.stop()


def start_loop(loop):
    asyncio.set_event_loop(loop)
    loop.run_forever()


def create_and_run_threads(filename_list):
    # 根据文件名创建线程并处理对应的文件
    threads = []
    for filename in filename_list:
        loop = asyncio.new_event_loop()
        t = threading.Thread(target=start_loop, args=(loop,), name=filename)
        threads.append((t, loop, filename))
    # 启动线程
    for t in threads:
        t[0].start()
        asyncio.run_coroutine_threadsafe(process(t[2]), t[1])
    # 阻塞进程至线程结束
    for t in threads:
        t[0].join()


if __name__ == '__main__':
    # 初始化目标文件名数据
    start_time = time.time()
    sort_filename_list = [str(i)+"-data.txt" for i in range(10)]
    create_and_run_threads(sort_filename_list)
    end_time = time.time()
    print("用时{}秒".format(end_time-start_time))
    print('内存使用：{} Mb'.format(psutil.Process(os.getpid()).memory_info().rss/1024**2))

```
> 思路：将每个文件读取一个 chunk_size 的数据，每个 chunk_size 的数据排序后保存至一个临时文件，将文件名保存至一个列表，用于使用归并算法，使用归并算法，将每两个文件归并至一个新文件，将新文件名保存，返回最终结果文件名。
>
> 排序使用了线程+协程的方式，10个文件创建了10个线程，每个线程内部，有自己的协程，用于创建临时文件，本机测试，比纯线程方式快约30s。对整个文件的排序大约需要305s，内存使用约24mb，分析原因在I/O等待时间较长以及，python 动态语言的缺点造成。

## 结果检查
```python
import threading

interval = 1e+7


def check(f_name, inter):
    """
    检查对应结果文件中，排序结果是否准确
    :param f_name: 结果文件名
    :param inter: 数据与对应行号的差值
    :return: None
    """
    print("{} checking".format(f_name))
    with open(f_name, "rt") as f:
        for k, v in enumerate(f):
            if k != int(v) - inter:
                print(f_name, "err")
                return
    print(f_name, "ok")


if __name__ == '__main__':
    filename_list = [str(i) + "-data-ans.txt" for i in range(10)]
    tmp = 0
    threads = []
    # 使用多线程检查结果正确性
    for filename in filename_list:
        t = threading.Thread(target=check, args=(filename, tmp))
        threads.append(t)
        tmp += interval
    for t in threads:
        t.start()
    for t in threads:
        t.join()

```

## 输出
```python
if __name__ == '__main__':
    # 按顺序将文件中的数据打印出
    filename_list = [str(i) + "-data-ans.txt" for i in range(10)]
    for filename in filename_list:
        print("Result of {}".format(filename))
        with open(filename, 'rt') as f:
            for k, v in enumerate(f):
                print("No.{} value={}".format(k, v), end="")

```